{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import urllib2\n",
    "import math\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "# from gensim import corpora\n",
    "# from gensim.models import LdaMulticore\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import defaultdict\n",
    "import copy as cp\n",
    "from bs4 import BeautifulSoup\n",
    "from functools import reduce \n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import datetime\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2013-2016 emergence of populist concerns \n",
    "# Frequency of Populist key words \n",
    "#data_file = '~/Documents/Small Projects/AAPOR_2018/Populism/'\n",
    "data_file = '~/Documents/personal/aapor_politics_2018/'\n",
    "populist_posts = pd.read_csv(data_file + \"populist_comments_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#redo with more data \n",
    "data = os.listdir(\"all_populist\")\n",
    "\n",
    "df_from_each_file = (pd.read_csv(f) for f in all_files)\n",
    "concatenated_df   = pd.concat((pd.read_csv(f,header=None,skip_rows=1) for f in data), ignore_index=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "populist_posts['year'] = populist_posts['time_created'].apply(lambda x :datetime.datetime.fromtimestamp(x).year)\n",
    "populist_posts['month'] = populist_posts['time_created'].apply(lambda x :datetime.datetime.fromtimestamp(x).month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data = populist_posts #just rename to make it faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_topic_model = shuffle(populist_posts)\n",
    "#[:20000]\n",
    "data = train_topic_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1397056, 11)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make a subclass of the vectorizer that lemmatizes so we don't end up with wierd truncations\n",
    "# lemm = WordNetLemmatizer()\n",
    "# class LemmaCountVectorizer(CountVectorizer):\n",
    "#     def build_analyzer(self):\n",
    "#         analyzer = super(LemmaCountVectorizer, self).build_analyzer()\n",
    "#         return lambda doc: (lemm.lemmatize(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_text = list(data['body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Top Words used by Subreddit and Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top_words(text):\n",
    "    tf_vectorizer = CountVectorizer(max_df=0.95, \n",
    "                                         min_df=len(text)/100,\n",
    "                                         stop_words='english',\n",
    "                                         decode_error='ignore')\n",
    "    tf = tf_vectorizer.fit_transform(text)\n",
    "    feature_names = tf_vectorizer.get_feature_names()\n",
    "    count_vec = np.asarray(tf.sum(axis=0)).ravel()\n",
    "    zipped = list(zip(feature_names, count_vec))\n",
    "    words, freqs = (list(x) for x in zip(*sorted(zipped, key=lambda x: x[1], reverse=True)))\n",
    "    words = words[:40]\n",
    "    freqs = freqs[:40]\n",
    "    return words\n",
    "#     top_words = pd.DataFrame([words, freqs]).T\n",
    "#     top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'trump',\n",
       " u'people',\n",
       " u'gt',\n",
       " u'just',\n",
       " u'like',\n",
       " u'don',\n",
       " u'clinton',\n",
       " u'white',\n",
       " u'think',\n",
       " u'com',\n",
       " u'www',\n",
       " u'right',\n",
       " u'http',\n",
       " u'know',\n",
       " u'hillary',\n",
       " u'going',\n",
       " u'said',\n",
       " u'sanders',\n",
       " u'https',\n",
       " u'want',\n",
       " u'make',\n",
       " u'time',\n",
       " u'did',\n",
       " u'say',\n",
       " u'politics',\n",
       " u'really',\n",
       " u'way',\n",
       " u'doesn',\n",
       " u'vote',\n",
       " u'president',\n",
       " u'actually',\n",
       " u'good',\n",
       " u'country',\n",
       " u'does',\n",
       " u'obama',\n",
       " u'isn',\n",
       " u'didn',\n",
       " u'news',\n",
       " u'point',\n",
       " u'thing']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the top words\n",
    "get_top_words(list(data['body']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worldnews\n",
      "news\n",
      "history\n",
      "politics\n",
      "democrats\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worldnews</th>\n",
       "      <th>news</th>\n",
       "      <th>history</th>\n",
       "      <th>politics</th>\n",
       "      <th>democrats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>people</td>\n",
       "      <td>people</td>\n",
       "      <td>war</td>\n",
       "      <td>trump</td>\n",
       "      <td>trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trump</td>\n",
       "      <td>white</td>\n",
       "      <td>people</td>\n",
       "      <td>people</td>\n",
       "      <td>sanders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gt</td>\n",
       "      <td>trump</td>\n",
       "      <td>white</td>\n",
       "      <td>clinton</td>\n",
       "      <td>clinton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>just</td>\n",
       "      <td>just</td>\n",
       "      <td>history</td>\n",
       "      <td>gt</td>\n",
       "      <td>people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>like</td>\n",
       "      <td>like</td>\n",
       "      <td>like</td>\n",
       "      <td>just</td>\n",
       "      <td>gt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>don</td>\n",
       "      <td>gt</td>\n",
       "      <td>time</td>\n",
       "      <td>like</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>islam</td>\n",
       "      <td>don</td>\n",
       "      <td>just</td>\n",
       "      <td>don</td>\n",
       "      <td>don</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>think</td>\n",
       "      <td>black</td>\n",
       "      <td>gt</td>\n",
       "      <td>think</td>\n",
       "      <td>just</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>http</td>\n",
       "      <td>think</td>\n",
       "      <td>did</td>\n",
       "      <td>com</td>\n",
       "      <td>hillary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>com</td>\n",
       "      <td>right</td>\n",
       "      <td>com</td>\n",
       "      <td>hillary</td>\n",
       "      <td>bernie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>white</td>\n",
       "      <td>know</td>\n",
       "      <td>https</td>\n",
       "      <td>sanders</td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>right</td>\n",
       "      <td>say</td>\n",
       "      <td>combat</td>\n",
       "      <td>www</td>\n",
       "      <td>think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>world</td>\n",
       "      <td>want</td>\n",
       "      <td>www</td>\n",
       "      <td>white</td>\n",
       "      <td>vote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>know</td>\n",
       "      <td>time</td>\n",
       "      <td>world</td>\n",
       "      <td>politics</td>\n",
       "      <td>http</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>www</td>\n",
       "      <td>com</td>\n",
       "      <td>think</td>\n",
       "      <td>right</td>\n",
       "      <td>party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>country</td>\n",
       "      <td>make</td>\n",
       "      <td>amp</td>\n",
       "      <td>know</td>\n",
       "      <td>democrats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>want</td>\n",
       "      <td>said</td>\n",
       "      <td>don</td>\n",
       "      <td>going</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>said</td>\n",
       "      <td>way</td>\n",
       "      <td>really</td>\n",
       "      <td>https</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>say</td>\n",
       "      <td>going</td>\n",
       "      <td>http</td>\n",
       "      <td>vote</td>\n",
       "      <td>know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>make</td>\n",
       "      <td>did</td>\n",
       "      <td>know</td>\n",
       "      <td>said</td>\n",
       "      <td>supporters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>time</td>\n",
       "      <td>really</td>\n",
       "      <td>way</td>\n",
       "      <td>http</td>\n",
       "      <td>want</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>way</td>\n",
       "      <td>www</td>\n",
       "      <td>years</td>\n",
       "      <td>president</td>\n",
       "      <td>going</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>islamic</td>\n",
       "      <td>http</td>\n",
       "      <td>american</td>\n",
       "      <td>did</td>\n",
       "      <td>obama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>muslims</td>\n",
       "      <td>doesn</td>\n",
       "      <td>islam</td>\n",
       "      <td>bernie</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>did</td>\n",
       "      <td>isn</td>\n",
       "      <td>british</td>\n",
       "      <td>make</td>\n",
       "      <td>www</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>really</td>\n",
       "      <td>islam</td>\n",
       "      <td>message</td>\n",
       "      <td>time</td>\n",
       "      <td>make</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>going</td>\n",
       "      <td>police</td>\n",
       "      <td>empire</td>\n",
       "      <td>really</td>\n",
       "      <td>did</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>terrorism</td>\n",
       "      <td>racist</td>\n",
       "      <td>good</td>\n",
       "      <td>say</td>\n",
       "      <td>campaign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>doesn</td>\n",
       "      <td>actually</td>\n",
       "      <td>german</td>\n",
       "      <td>want</td>\n",
       "      <td>president</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>government</td>\n",
       "      <td>good</td>\n",
       "      <td>black</td>\n",
       "      <td>doesn</td>\n",
       "      <td>said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>war</td>\n",
       "      <td>thing</td>\n",
       "      <td>didn</td>\n",
       "      <td>way</td>\n",
       "      <td>voters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>muslim</td>\n",
       "      <td>ve</td>\n",
       "      <td>army</td>\n",
       "      <td>obama</td>\n",
       "      <td>election</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>does</td>\n",
       "      <td>does</td>\n",
       "      <td>great</td>\n",
       "      <td>party</td>\n",
       "      <td>amp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>countries</td>\n",
       "      <td>country</td>\n",
       "      <td>europe</td>\n",
       "      <td>actually</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>good</td>\n",
       "      <td>point</td>\n",
       "      <td>military</td>\n",
       "      <td>election</td>\n",
       "      <td>way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>actually</td>\n",
       "      <td>things</td>\n",
       "      <td>org</td>\n",
       "      <td>didn</td>\n",
       "      <td>democratic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>russia</td>\n",
       "      <td>didn</td>\n",
       "      <td>new</td>\n",
       "      <td>reddit</td>\n",
       "      <td>really</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>state</td>\n",
       "      <td>saying</td>\n",
       "      <td>lot</td>\n",
       "      <td>good</td>\n",
       "      <td>won</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>isn</td>\n",
       "      <td>shit</td>\n",
       "      <td>used</td>\n",
       "      <td>does</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>years</td>\n",
       "      <td>news</td>\n",
       "      <td>submission</td>\n",
       "      <td>supporters</td>\n",
       "      <td>need</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     worldnews      news     history    politics   democrats\n",
       "0       people    people         war       trump       trump\n",
       "1        trump     white      people      people     sanders\n",
       "2           gt     trump       white     clinton     clinton\n",
       "3         just      just     history          gt      people\n",
       "4         like      like        like        just          gt\n",
       "5          don        gt        time        like        like\n",
       "6        islam       don        just         don         don\n",
       "7        think     black          gt       think        just\n",
       "8         http     think         did         com     hillary\n",
       "9          com     right         com     hillary      bernie\n",
       "10       white      know       https     sanders         com\n",
       "11       right       say      combat         www       think\n",
       "12       world      want         www       white        vote\n",
       "13        know      time       world    politics        http\n",
       "14         www       com       think       right       party\n",
       "15     country      make         amp        know   democrats\n",
       "16        want      said         don       going       right\n",
       "17        said       way      really       https       white\n",
       "18         say     going        http        vote        know\n",
       "19        make       did        know        said  supporters\n",
       "20        time    really         way        http        want\n",
       "21         way       www       years   president       going\n",
       "22     islamic      http    american         did       obama\n",
       "23     muslims     doesn       islam      bernie        time\n",
       "24         did       isn     british        make         www\n",
       "25      really     islam     message        time        make\n",
       "26       going    police      empire      really         did\n",
       "27   terrorism    racist        good         say    campaign\n",
       "28       doesn  actually      german        want   president\n",
       "29  government      good       black       doesn        said\n",
       "30         war     thing        didn         way      voters\n",
       "31      muslim        ve        army       obama    election\n",
       "32        does      does       great       party         amp\n",
       "33   countries   country      europe    actually         win\n",
       "34        good     point    military    election         way\n",
       "35    actually    things         org        didn  democratic\n",
       "36      russia      didn         new      reddit      really\n",
       "37       state    saying         lot        good         won\n",
       "38         isn      shit        used        does      reddit\n",
       "39       years      news  submission  supporters        need"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_subreddits = ['worldnews','news','history','politics', 'democrats'] #these are the largest\n",
    "top_words_grid = []\n",
    "cols = []\n",
    "for subreddit in list_of_subreddits:\n",
    "    cols.append(subreddit)\n",
    "    top_words_grid.append( get_top_words(list(data[data['subreddit']==subreddit]['body'])))\n",
    "    print subreddit\n",
    "top_words_df = pd.DataFrame(top_words_grid).T\n",
    "top_words_df.columns = cols\n",
    "top_words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>people</td>\n",
       "      <td>people</td>\n",
       "      <td>people</td>\n",
       "      <td>trump</td>\n",
       "      <td>trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>white</td>\n",
       "      <td>gt</td>\n",
       "      <td>gt</td>\n",
       "      <td>people</td>\n",
       "      <td>people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gt</td>\n",
       "      <td>white</td>\n",
       "      <td>just</td>\n",
       "      <td>clinton</td>\n",
       "      <td>gt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>just</td>\n",
       "      <td>just</td>\n",
       "      <td>like</td>\n",
       "      <td>gt</td>\n",
       "      <td>just</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>like</td>\n",
       "      <td>like</td>\n",
       "      <td>white</td>\n",
       "      <td>just</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>don</td>\n",
       "      <td>don</td>\n",
       "      <td>don</td>\n",
       "      <td>like</td>\n",
       "      <td>don</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>http</td>\n",
       "      <td>http</td>\n",
       "      <td>think</td>\n",
       "      <td>don</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>think</td>\n",
       "      <td>think</td>\n",
       "      <td>trump</td>\n",
       "      <td>hillary</td>\n",
       "      <td>think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>com</td>\n",
       "      <td>www</td>\n",
       "      <td>sanders</td>\n",
       "      <td>think</td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>www</td>\n",
       "      <td>com</td>\n",
       "      <td>com</td>\n",
       "      <td>sanders</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>government</td>\n",
       "      <td>black</td>\n",
       "      <td>http</td>\n",
       "      <td>com</td>\n",
       "      <td>www</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>islam</td>\n",
       "      <td>islam</td>\n",
       "      <td>www</td>\n",
       "      <td>white</td>\n",
       "      <td>know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>know</td>\n",
       "      <td>right</td>\n",
       "      <td>clinton</td>\n",
       "      <td>www</td>\n",
       "      <td>https</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>right</td>\n",
       "      <td>know</td>\n",
       "      <td>islam</td>\n",
       "      <td>vote</td>\n",
       "      <td>said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>black</td>\n",
       "      <td>want</td>\n",
       "      <td>right</td>\n",
       "      <td>bernie</td>\n",
       "      <td>president</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          2013    2014     2015     2016       2017\n",
       "0       people  people   people    trump      trump\n",
       "1        white      gt       gt   people     people\n",
       "2           gt   white     just  clinton         gt\n",
       "3         just    just     like       gt       just\n",
       "4         like    like    white     just       like\n",
       "5          don     don      don     like        don\n",
       "6         http    http    think      don      white\n",
       "7        think   think    trump  hillary      think\n",
       "8          com     www  sanders    think        com\n",
       "9          www     com      com  sanders      right\n",
       "10  government   black     http      com        www\n",
       "11       islam   islam      www    white       know\n",
       "12        know   right  clinton      www      https\n",
       "13       right    know    islam     vote       said\n",
       "14       black    want    right   bernie  president"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words_grid_yr = []\n",
    "year_list = []\n",
    "for year in [2013, 2014, 2015, 2016, 2017]:\n",
    "    year_list.append(year)\n",
    "    top_words_grid_yr.append(get_top_words(list(data[data['year']==year]['body'])))\n",
    "    print year\n",
    "top_words_df_year = pd.DataFrame(top_words_grid_yr).T\n",
    "top_words_df_year.columns = year_list\n",
    "top_words_df_year.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(max_df=0.95, \n",
    "                                         min_df=len(all_text)/1000,\n",
    "                                         stop_words='english',\n",
    "                                         decode_error='ignore')\n",
    "transformed_text = tf_vectorizer.fit_transform(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=5, mean_change_tol=0.001,\n",
       "             n_components=15, n_jobs=1, n_topics=None, perp_tol=0.1,\n",
       "             random_state=0, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model = LatentDirichletAllocation(n_components=15, max_iter=5,\n",
    "                                learning_method = 'online',\n",
    "                                random_state = 0)\n",
    "\n",
    "topic_model.fit(transformed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'https', u'twitter', u'current', u'politics', u'com', u'rules', u'original', u'np', u'bot']\n",
      "______________________________\n",
      "[u'gt', u'news', u'said', u'article', u'israel', u'anti', u'read', u'jews', u'fox']\n",
      "______________________________\n",
      "[u'obama', u'party', u'got', u'case', u'bush', u'votes', u'new', u'years', u'congress']\n",
      "______________________________\n",
      "[u'white', u'people', u'black', u'racist', u'seen', u'police', u'crime', u'violence', u'men']\n",
      "______________________________\n",
      "[u'politics', u'reddit', u'amp', u'com', u'https', u'www', u'comments', u'message', u'removal']\n",
      "______________________________\n",
      "[u'islam', u'war', u'world', u'muslims', u'muslim', u'islamic', u'country', u'countries', u'middle']\n",
      "______________________________\n",
      "[u'right', u'maybe', u'media', u'100', u'fake', u'wing', u'trumps', u'unless', u'speech']\n",
      "______________________________\n",
      "[u'immigration', u'government', u'money', u'illegal', u'tax', u'years', u'country', u'work', u'job']\n",
      "______________________________\n",
      "[u'people', u'wrong', u'saying', u'different', u'america', u'little', u'race', u'idea', u'point']\n",
      "______________________________\n",
      "[u'http', u'com', u'www', u'house', u'2016', u'html', u'court', u'10', u'private']\n",
      "______________________________\n",
      "[u'trump', u'like', u'just', u'don', u'people', u'think', u'know', u'say', u'really']\n",
      "______________________________\n",
      "[u'clinton', u'hillary', u'sanders', u'trump', u'bernie', u'supporters', u'campaign', u'didn', u'dnc']\n",
      "______________________________\n",
      "[u'trump', u'vote', u'election', u'people', u'won', u'republicans', u'candidate', u'win', u'democrats']\n",
      "______________________________\n",
      "[u'org', u'terrorism', u'https', u'states', u'state', u'political', u'military', u'watch', u'united']\n",
      "______________________________\n",
      "[u'trump', u'president', u'russia', u'donald', u'russian', u'investigation', u'fbi', u'putin', u'said']\n",
      "______________________________\n"
     ]
    }
   ],
   "source": [
    "feature_names = tf_vectorizer.get_feature_names()\n",
    "for topic in topic_model.components_:\n",
    "    word_ixes = topic.argsort()[:-10:-1]\n",
    "    words = [feature_names[i] for i in word_ixes]\n",
    "    print words\n",
    "    print \"______________________________\"\n",
    "#labels \n",
    "labels = [\"Obama\",\"Brexit\",\"Trump: Scandals\",\"Sanders\",\"World Politics\",\"Partisan Politics\",\"Islam\",\"Immigration\",\n",
    "          \"Trump: Presidency\",\"Colloquial speach\",\"Clinton\",\"Russia\",\"Race\",\"Internet\",\"Terrorism\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def which_topic(topic_model, text):\n",
    "    '''\n",
    "    Helper function to return a random topic if the best match is tied\n",
    "    '''\n",
    "    x = topic_model.transform(tf_vectorizer.transform([text]))[0]\n",
    "    max_value = x[x.argsort()[-1]]\n",
    "    possible_topics = []\n",
    "    for index, value in enumerate(x):\n",
    "        if value == max_value:\n",
    "            possible_topics.append(index)\n",
    "    return np.random.choice(possible_topics, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ckelley/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data['topic'] = data['body'].apply(lambda x: which_topic(topic_model,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>downs</th>\n",
       "      <th>score</th>\n",
       "      <th>time_created</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>month_created</th>\n",
       "      <th>selector</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>220869</th>\n",
       "      <td>Yeah, this is basically how I view it. I think...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1475102539</td>\n",
       "      <td>Cuckberg</td>\n",
       "      <td>politics</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539983</th>\n",
       "      <td>&amp;gt;If Trump cuts taxes by every Hillary suppo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1478911937</td>\n",
       "      <td>mrrp</td>\n",
       "      <td>politics</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213255</th>\n",
       "      <td>Urm no, it's a perfectly legit question, someo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1475066137</td>\n",
       "      <td>Quagers</td>\n",
       "      <td>ukpolitics</td>\n",
       "      <td>t5_2qhcv</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260436</th>\n",
       "      <td>The point is that he DID say something. And in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1502738136</td>\n",
       "      <td>kylethemurphy</td>\n",
       "      <td>politics</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312474</th>\n",
       "      <td>Is there anything Sanders HASN'T promised yet?...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1431695035</td>\n",
       "      <td>Jura52</td>\n",
       "      <td>politics</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     body  downs  score  \\\n",
       "220869  Yeah, this is basically how I view it. I think...    NaN    2.0   \n",
       "539983  &gt;If Trump cuts taxes by every Hillary suppo...    NaN    NaN   \n",
       "213255  Urm no, it's a perfectly legit question, someo...    NaN    5.0   \n",
       "260436  The point is that he DID say something. And in...    NaN    NaN   \n",
       "312474  Is there anything Sanders HASN'T promised yet?...    0.0    2.0   \n",
       "\n",
       "        time_created         author   subreddit subreddit_id  month_created  \\\n",
       "220869    1475102539       Cuckberg    politics     t5_2cneq              1   \n",
       "539983    1478911937           mrrp    politics     t5_2cneq              1   \n",
       "213255    1475066137        Quagers  ukpolitics     t5_2qhcv              1   \n",
       "260436    1502738136  kylethemurphy    politics     t5_2cneq              1   \n",
       "312474    1431695035         Jura52    politics     t5_2cneq              1   \n",
       "\n",
       "        selector  year  month  topic  \n",
       "220869         3  2016      9      6  \n",
       "539983         3  2016     11      7  \n",
       "213255         3  2016      9      8  \n",
       "260436         3  2017      8      8  \n",
       "312474         3  2015      5      1  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ckelley/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/Users/ckelley/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#try excepts are to skip unicode errors which I don't want to deal with\n",
    "#Somewhat slow on partial data (~30 sec)\n",
    "def get_polarity(text):\n",
    "    try:\n",
    "        return TextBlob(text).sentiment.polarityt\n",
    "    except:\n",
    "        return np.nan\n",
    "def get_subjectivity(text):\n",
    "    try:\n",
    "        return TextBlob(text).sentiment.subjectivity\n",
    "    except:\n",
    "        return np.nan\n",
    "data['polarity'] = data['body'].apply(lambda x: get_polarity(x))\n",
    "data['subjectivity'] = data['body'].apply(lambda x: get_subjectivity(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Up and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#topic balance over time, I'm imagining one of those area plots\n",
    "topics_over_time = data.groupby(['year', 'month', 'topic']).agg({'body': 'count'}).reset_index().rename(columns = {'body':'count'})\n",
    "topics_over_time.to_csv(\"topics_over_time.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_over_time = data.groupby(['year', 'month']).agg({'polarity': np.mean, 'subjectivity': np.mean})\n",
    "#use this to make a  line graph, show that polarity isn't hugely changing ovet time neither is subjectivity\n",
    "sentiment_over_time.to_csv(\"sentiment_over_times.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.139685</td>\n",
       "      <td>0.387926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.041612</td>\n",
       "      <td>0.382984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.050321</td>\n",
       "      <td>0.335446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008691</td>\n",
       "      <td>0.354988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.103581</td>\n",
       "      <td>0.359253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       polarity  subjectivity\n",
       "topic                        \n",
       "0      0.139685      0.387926\n",
       "1      0.041612      0.382984\n",
       "2      0.050321      0.335446\n",
       "3      0.008691      0.354988\n",
       "4      0.103581      0.359253"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_by_topic = data.groupby('topic').agg({'subjectivity': np.mean, 'polarity': np.mean, })\n",
    "#also not big differences by topic\n",
    "sentiment_by_topic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>downs</th>\n",
       "      <th>score</th>\n",
       "      <th>time_created</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>month_created</th>\n",
       "      <th>selector</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>topic</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>Clinton</th>\n",
       "      <th>Trump</th>\n",
       "      <th>altright</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1364757</th>\n",
       "      <td>&amp;gt;charlatan\\n\\nis the perfect word to descri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1485112032</td>\n",
       "      <td>II-III-V-VII-XI</td>\n",
       "      <td>politics</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456682</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Narcissistic_per...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1462978137</td>\n",
       "      <td>StonerMeditation</td>\n",
       "      <td>politics</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290375</th>\n",
       "      <td>&amp;gt; inept and corrupt\\n\\naka Donald Trump.\\n\\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1495756535</td>\n",
       "      <td>busmans</td>\n",
       "      <td>politics</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600770</th>\n",
       "      <td>NK are brilliant, they had to know the time of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1487053137</td>\n",
       "      <td>branager</td>\n",
       "      <td>politics</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211070</th>\n",
       "      <td>Evidence: [1](https://www.theguardian.com/poli...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1498209331</td>\n",
       "      <td>rumdiary</td>\n",
       "      <td>ukpolitics</td>\n",
       "      <td>t5_2qhcv</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.7500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014465</th>\n",
       "      <td>Careful. Math like that, Trump might try and h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1489691332</td>\n",
       "      <td>MisfortunateFox</td>\n",
       "      <td>politics</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298102</th>\n",
       "      <td>The Trump supports will still argue against th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1449709936</td>\n",
       "      <td>Grudgecrown</td>\n",
       "      <td>politics</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963494</th>\n",
       "      <td>\"In honor of all of the victims of the very sa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1506950738</td>\n",
       "      <td>Sessions4Prison</td>\n",
       "      <td>politics</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.8125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599574</th>\n",
       "      <td>Will Trump turn into a kaiju on November 9th a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1476289235</td>\n",
       "      <td>Tarlcabot18</td>\n",
       "      <td>politics</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53162</th>\n",
       "      <td>Trump Supporters:\"You cant trust the media\".\\n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1476911833</td>\n",
       "      <td>mwinks99</td>\n",
       "      <td>politics</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227613</th>\n",
       "      <td>Not to mention his playground level response o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1492566838</td>\n",
       "      <td>Xavs42</td>\n",
       "      <td>politics</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326781</th>\n",
       "      <td>Elections aren't won by convincing swing voter...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1464785835</td>\n",
       "      <td>xahhfink6</td>\n",
       "      <td>politics</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346822</th>\n",
       "      <td>check it out. http://datatitian.com/why-voxs-n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1459143931</td>\n",
       "      <td>LalalalaLakers</td>\n",
       "      <td>politics</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677387</th>\n",
       "      <td>Because nobody knows who the hell he is, perha...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1436206138</td>\n",
       "      <td>TheOneForPornStuff</td>\n",
       "      <td>politics</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.6000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144987</th>\n",
       "      <td>Oh dear god. They're going to crucify Clinton ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1494371839</td>\n",
       "      <td>coffeeisking</td>\n",
       "      <td>politics</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.8000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      body  downs  score  \\\n",
       "1364757  &gt;charlatan\\n\\nis the perfect word to descri...    NaN    NaN   \n",
       "456682   https://en.wikipedia.org/wiki/Narcissistic_per...    NaN    3.0   \n",
       "1290375    &gt; inept and corrupt\\n\\naka Donald Trump.\\n\\n    NaN    NaN   \n",
       "600770   NK are brilliant, they had to know the time of...    NaN    NaN   \n",
       "1211070  Evidence: [1](https://www.theguardian.com/poli...    NaN    NaN   \n",
       "1014465  Careful. Math like that, Trump might try and h...    NaN    NaN   \n",
       "298102   The Trump supports will still argue against th...    NaN    0.0   \n",
       "963494   \"In honor of all of the victims of the very sa...    NaN    NaN   \n",
       "599574   Will Trump turn into a kaiju on November 9th a...    NaN    NaN   \n",
       "53162    Trump Supporters:\"You cant trust the media\".\\n...    NaN    NaN   \n",
       "1227613  Not to mention his playground level response o...    NaN    NaN   \n",
       "1326781  Elections aren't won by convincing swing voter...    NaN    6.0   \n",
       "346822   check it out. http://datatitian.com/why-voxs-n...    NaN   -1.0   \n",
       "677387   Because nobody knows who the hell he is, perha...    0.0    6.0   \n",
       "1144987  Oh dear god. They're going to crucify Clinton ...    NaN    NaN   \n",
       "\n",
       "         time_created              author   subreddit subreddit_id  \\\n",
       "1364757    1485112032     II-III-V-VII-XI    politics     t5_2cneq   \n",
       "456682     1462978137    StonerMeditation    politics     t5_2cneq   \n",
       "1290375    1495756535             busmans    politics     t5_2cneq   \n",
       "600770     1487053137            branager    politics     t5_2cneq   \n",
       "1211070    1498209331            rumdiary  ukpolitics     t5_2qhcv   \n",
       "1014465    1489691332     MisfortunateFox    politics     t5_2cneq   \n",
       "298102     1449709936         Grudgecrown    politics     t5_2cneq   \n",
       "963494     1506950738     Sessions4Prison    politics     t5_2cneq   \n",
       "599574     1476289235         Tarlcabot18    politics     t5_2cneq   \n",
       "53162      1476911833            mwinks99    politics     t5_2cneq   \n",
       "1227613    1492566838              Xavs42    politics     t5_2cneq   \n",
       "1326781    1464785835           xahhfink6    politics     t5_2cneq   \n",
       "346822     1459143931      LalalalaLakers    politics     t5_2cneq   \n",
       "677387     1436206138  TheOneForPornStuff    politics     t5_2cneq   \n",
       "1144987    1494371839        coffeeisking    politics     t5_2cneq   \n",
       "\n",
       "         month_created  selector  year  month  topic  polarity  subjectivity  \\\n",
       "1364757              1         3  2017      1      1    1.0000           1.0   \n",
       "456682               1         3  2016      5     13    1.0000           1.0   \n",
       "1290375              1         3  2017      5      8   -0.5000           1.0   \n",
       "600770               1         3  2017      2     14    0.9000           1.0   \n",
       "1211070              1         3  2017      6      9   -0.7500           1.0   \n",
       "1014465              1         3  2017      3     14   -0.1000           1.0   \n",
       "298102               1         3  2015     12     10   -0.5000           1.0   \n",
       "963494               1         3  2017     10      6   -0.8125           1.0   \n",
       "599574               1         3  2016     10     12   -0.5000           1.0   \n",
       "53162                1         3  2016     10     11   -1.0000           1.0   \n",
       "1227613              1         3  2017      4      1    0.9000           1.0   \n",
       "1326781              1         3  2016      6     12    0.5000           1.0   \n",
       "346822               1         3  2016      3      7    0.1000           1.0   \n",
       "677387               1         3  2015      7     10   -0.6000           1.0   \n",
       "1144987              1         3  2017      5     12   -0.8000           1.0   \n",
       "\n",
       "         Clinton  Trump  altright  \n",
       "1364757    False   True     False  \n",
       "456682     False   True     False  \n",
       "1290375    False   True     False  \n",
       "600770     False   True     False  \n",
       "1211070    False  False     False  \n",
       "1014465    False   True     False  \n",
       "298102     False   True     False  \n",
       "963494     False   True     False  \n",
       "599574     False   True     False  \n",
       "53162      False   True     False  \n",
       "1227613    False   True     False  \n",
       "1326781     True   True     False  \n",
       "346822     False  False     False  \n",
       "677387      True  False     False  \n",
       "1144987     True  False     False  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find very negative tweet\n",
    "min(data['subjectivity'])\n",
    "data[data['subjectivity']==1].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Oh dear god. They're going to crucify Clinton to unite their base while solidifying  power.\""
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['body'].ix[1144987]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ckelley/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/ckelley/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data['Clinton'] = data['body'].apply(lambda x : True if 'clinton' in x.lower() or 'hilary' in x.lower() else False)\n",
    "data['Trump'] = data['body'].apply(lambda x : True if 'trump' in x.lower() or 'donald' in x.lower() else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ckelley/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data['altright'] = data['body'].apply(lambda x : True if 'alt-right' in x.lower() or 'alt right' in x.lower() else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06350303471948061, 0.04926718134116553)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinton_sentiment = np.mean(data[data['Clinton']]['polarity'])\n",
    "trump_sentiment = np.mean(data[data['Trump']]['polarity'])\n",
    "clinton_sentiment, trump_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinton_over_time = data[data['Clinton']].groupby(['year', 'month']).agg({'polarity': np.mean, 'subjectivity': np.mean, 'body': 'count'}).rename(columns= {'body': 'post_count'})\n",
    "clinton_over_time.to_csv(\"clinton_polarity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_over_time = data[data['Trump']].groupby(['year', 'month']).agg({'polarity': np.mean, 'subjectivity': np.mean, 'body': 'count'}).rename(columns= {'body': 'post_count'})\n",
    "trump_over_time.to_csv(\"trump_polarity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alt_over_time = data[data['altright']].groupby(['year', 'month']).agg({'polarity': np.mean, 'subjectivity': np.mean, 'body': 'count'}).rename(columns= {'body': 'post_count'})\n",
    "alt_over_time.to_csv(\"altright_polarity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit\n",
       "business               14\n",
       "democrats              48\n",
       "education               2\n",
       "energy                  5\n",
       "environment            22\n",
       "feminisms               6\n",
       "history                70\n",
       "law                    26\n",
       "moderatepolitics       16\n",
       "news                 2369\n",
       "politics            13012\n",
       "progressive            24\n",
       "racism                  8\n",
       "socialism             113\n",
       "ukpolitics            685\n",
       "uspolitics             10\n",
       "worldevents             5\n",
       "worldnews            3457\n",
       "worldpolitics         108\n",
       "Name: body, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('subreddit')['body'].count() #not enough in a lot of subreddits for much divided analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (optional) Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sentiment Analysis "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
