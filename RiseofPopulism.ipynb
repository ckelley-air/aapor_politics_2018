{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import urllib2\n",
    "import math\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "# from gensim import corpora\n",
    "# from gensim.models import LdaMulticore\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import defaultdict\n",
    "import copy as cp\n",
    "from bs4 import BeautifulSoup\n",
    "from functools import reduce \n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import datetime\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2013-2016 emergence of populist concerns \n",
    "# Frequency of Populist key words \n",
    "data_file = '~/Documents/Small Projects/AAPOR_2018/Populism/'\n",
    "populist_posts = pd.read_csv(data_file + \"populist_comments_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "populist_posts['year'] = populist_posts['time_created'].apply(lambda x :datetime.datetime.fromtimestamp(x).year)\n",
    "populist_posts['month'] = populist_posts['time_created'].apply(lambda x :datetime.datetime.fromtimestamp(x).month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data = populist_posts #just rename to make it faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_topic_model = shuffle(populist_posts)[:20000]\n",
    "data = train_topic_model\n",
    "#we only train on 20,000 entries because it otherwise takes soooooo long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a subclass of the vectorizer that lemmatizes so we don't end up with wierd truncations\n",
    "# lemm = WordNetLemmatizer()\n",
    "# class LemmaCountVectorizer(CountVectorizer):\n",
    "#     def build_analyzer(self):\n",
    "#         analyzer = super(LemmaCountVectorizer, self).build_analyzer()\n",
    "#         return lambda doc: (lemm.lemmatize(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_text = list(data['body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Top Words used by Subreddit and Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top_words(text):\n",
    "    tf_vectorizer = CountVectorizer(max_df=0.95, \n",
    "                                         min_df=len(text)/100,\n",
    "                                         stop_words='english',\n",
    "                                         decode_error='ignore')\n",
    "    tf = tf_vectorizer.fit_transform(text)\n",
    "    feature_names = tf_vectorizer.get_feature_names()\n",
    "    count_vec = np.asarray(tf.sum(axis=0)).ravel()\n",
    "    zipped = list(zip(feature_names, count_vec))\n",
    "    words, freqs = (list(x) for x in zip(*sorted(zipped, key=lambda x: x[1], reverse=True)))\n",
    "    words = words[:20]\n",
    "    freqs = freqs[:20]\n",
    "    return words\n",
    "#     top_words = pd.DataFrame([words, freqs]).T\n",
    "#     top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'trump',\n",
       " u'people',\n",
       " u'gt',\n",
       " u'just',\n",
       " u'like',\n",
       " u'don',\n",
       " u'clinton',\n",
       " u'white',\n",
       " u'think',\n",
       " u'com',\n",
       " u'www',\n",
       " u'right',\n",
       " u'http',\n",
       " u'know',\n",
       " u'hillary',\n",
       " u'going',\n",
       " u'said',\n",
       " u'https',\n",
       " u'politics',\n",
       " u'make']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the top words\n",
    "get_top_words(list(data['body']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worldnews\n",
      "news\n",
      "history\n",
      "politics\n",
      "democrats\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worldnews</th>\n",
       "      <th>news</th>\n",
       "      <th>history</th>\n",
       "      <th>politics</th>\n",
       "      <th>democrats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trump</td>\n",
       "      <td>people</td>\n",
       "      <td>amp</td>\n",
       "      <td>trump</td>\n",
       "      <td>trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>people</td>\n",
       "      <td>white</td>\n",
       "      <td>people</td>\n",
       "      <td>people</td>\n",
       "      <td>people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gt</td>\n",
       "      <td>trump</td>\n",
       "      <td>war</td>\n",
       "      <td>clinton</td>\n",
       "      <td>clinton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>just</td>\n",
       "      <td>just</td>\n",
       "      <td>white</td>\n",
       "      <td>gt</td>\n",
       "      <td>sanders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>like</td>\n",
       "      <td>like</td>\n",
       "      <td>like</td>\n",
       "      <td>just</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  worldnews    news history politics democrats\n",
       "0     trump  people     amp    trump     trump\n",
       "1    people   white  people   people    people\n",
       "2        gt   trump     war  clinton   clinton\n",
       "3      just    just   white       gt   sanders\n",
       "4      like    like    like     just      like"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_subreddits = ['worldnews','news','history','politics', 'democrats'] #these are the largest\n",
    "top_words_grid = []\n",
    "cols = []\n",
    "for subreddit in list_of_subreddits:\n",
    "    cols.append(subreddit)\n",
    "    top_words_grid.append( get_top_words(list(data[data['subreddit']==subreddit]['body'])))\n",
    "    print subreddit\n",
    "top_words_df = pd.DataFrame(top_words_grid).T\n",
    "top_words_df.columns = cols\n",
    "top_words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>people</td>\n",
       "      <td>people</td>\n",
       "      <td>people</td>\n",
       "      <td>trump</td>\n",
       "      <td>trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gt</td>\n",
       "      <td>white</td>\n",
       "      <td>gt</td>\n",
       "      <td>people</td>\n",
       "      <td>people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>white</td>\n",
       "      <td>just</td>\n",
       "      <td>just</td>\n",
       "      <td>clinton</td>\n",
       "      <td>gt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>just</td>\n",
       "      <td>like</td>\n",
       "      <td>white</td>\n",
       "      <td>gt</td>\n",
       "      <td>just</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>like</td>\n",
       "      <td>gt</td>\n",
       "      <td>like</td>\n",
       "      <td>just</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     2013    2014    2015     2016    2017\n",
       "0  people  people  people    trump   trump\n",
       "1      gt   white      gt   people  people\n",
       "2   white    just    just  clinton      gt\n",
       "3    just    like   white       gt    just\n",
       "4    like      gt    like     just    like"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words_grid_yr = []\n",
    "year_list = []\n",
    "for year in [2013, 2014, 2015, 2016, 2017]:\n",
    "    year_list.append(year)\n",
    "    top_words_grid_yr.append(get_top_words(list(data[data['year']==year]['body'])))\n",
    "    print year\n",
    "top_words_df_year = pd.DataFrame(top_words_grid_yr).T\n",
    "top_words_df_year.columns = year_list\n",
    "top_words_df_year.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(max_df=0.95, \n",
    "                                         min_df=len(all_text)/100,\n",
    "                                         stop_words='english',\n",
    "                                         decode_error='ignore')\n",
    "transformed_text = tf_vectorizer.fit_transform(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=5, mean_change_tol=0.001,\n",
       "             n_components=15, n_jobs=1, n_topics=None, perp_tol=0.1,\n",
       "             random_state=0, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model = LatentDirichletAllocation(n_components=15, max_iter=5,\n",
    "                                learning_method = 'online',\n",
    "                                random_state = 0)\n",
    "\n",
    "topic_model.fit(transformed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'trump', u'vote', u'party', u'supporters', u'election', u'republicans', u'win', u'republican', u'candidate']\n",
      "______________________________\n",
      "[u'look', u'don', u'yes', u'want', u'wasn', u'liberal', u'jobs', u'trumps', u'actual']\n",
      "______________________________\n",
      "[u'trump', u'just', u'like', u'doesn', u'thing', u'doing', u'right', u'know', u'media']\n",
      "______________________________\n",
      "[u'obama', u'war', u'didn', u'years', u'trump', u'wouldn', u'tell', u'help', u'office']\n",
      "______________________________\n",
      "[u'gt', u'right', u'law', u'illegal', u'immigrants', u'rights', u'police', u'religion', u'example']\n",
      "______________________________\n",
      "[u'politics', u'reddit', u'amp', u'com', u'message', u'https', u'comments', u'www', u'removal']\n",
      "______________________________\n",
      "[u'public', u'muslims', u'old', u'countries', u'immigration', u'eu', u'attack', u'dnc', u'fact']\n",
      "______________________________\n",
      "[u'com', u'http', u'www', u'https', u'2016', u'news', u'org', u'gt', u'article']\n",
      "______________________________\n",
      "[u'trump', u'president', u'russia', u'donald', u'russian', u'campaign', u'simply', u'putin', u'policies']\n",
      "______________________________\n",
      "[u'people', u'don', u'think', u'like', u'support', u'know', u'lot', u'just', u'money']\n",
      "______________________________\n",
      "[u'islam', u'terrorism', u'people', u'islamic', u'bad', u'muslim', u'means', u'problem', u'state']\n",
      "______________________________\n",
      "[u'clinton', u'hillary', u'sanders', u'bernie', u'house', u'campaign', u'did', u'lost', u'conservative']\n",
      "______________________________\n",
      "[u'white', u'people', u'black', u'racist', u'guy', u'gop', u'americans', u'american', u'like']\n",
      "______________________________\n",
      "[u'trump', u'just', u'going', u'll', u'time', u'like', u'actually', u'don', u'say']\n",
      "______________________________\n",
      "[u'reason', u'hate', u'women', u'start', u'class', u'better', u'makes', u'huge', u'question']\n",
      "______________________________\n"
     ]
    }
   ],
   "source": [
    "feature_names = tf_vectorizer.get_feature_names()\n",
    "for topic in topic_model.components_:\n",
    "    word_ixes = topic.argsort()[:-10:-1]\n",
    "    words = [feature_names[i] for i in word_ixes]\n",
    "    print words\n",
    "    print \"______________________________\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def which_topic(topic_model, text):\n",
    "    '''\n",
    "    Helper function to return a random topic if the best match is tied\n",
    "    '''\n",
    "    x = topic_model.transform(tf_vectorizer.transform([text]))[0]\n",
    "    max_value = x[x.argsort()[-1]]\n",
    "    possible_topics = []\n",
    "    for index, value in enumerate(x):\n",
    "        if value == max_value:\n",
    "            possible_topics.append(index)\n",
    "    return np.random.choice(possible_topics, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['topic'] = data['body'].apply(lambda x: which_topic(topic_model,x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try excepts are to skip unicode errors which I don't want to deal with\n",
    "#Somewhat slow on partial data (~30 sec)\n",
    "def get_polarity(text):\n",
    "    try:\n",
    "        return TextBlob(text).sentiment.polarity\n",
    "    except:\n",
    "        return np.nan\n",
    "def get_subjectivity(text):\n",
    "    try:\n",
    "        return TextBlob(text).sentiment.subjectivity\n",
    "    except:\n",
    "        return np.nan\n",
    "data['polarity'] = data['body'].apply(lambda x: get_polarity(x))\n",
    "data['subjectivity'] = data['body'].apply(lambda x: get_subjectivity(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Up and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>topic</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  topic  count\n",
       "0  2012     12     12      1\n",
       "1  2013      1      1      1\n",
       "2  2013      1      2      5\n",
       "3  2013      1      3      1\n",
       "4  2013      1      4      4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#topic balance over time, I'm imagining one of those area plots\n",
    "topics_over_time = data.groupby(['year', 'month', 'topic']).agg({'body': 'count'}).reset_index().rename(columns = {'body':'count'})\n",
    "topics_over_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <th>12</th>\n",
       "      <td>-0.242857</td>\n",
       "      <td>0.467262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2013</th>\n",
       "      <th>1</th>\n",
       "      <td>0.025298</td>\n",
       "      <td>0.454223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.064368</td>\n",
       "      <td>0.392500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.043157</td>\n",
       "      <td>0.415356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.036377</td>\n",
       "      <td>0.379031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            polarity  subjectivity\n",
       "year month                        \n",
       "2012 12    -0.242857      0.467262\n",
       "2013 1      0.025298      0.454223\n",
       "     2      0.064368      0.392500\n",
       "     3      0.043157      0.415356\n",
       "     4      0.036377      0.379031"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_over_time = data.groupby(['year', 'month']).agg({'polarity': np.mean, 'subjectivity': np.mean})\n",
    "#use this to make a  line graph, show that polarity isn't hugely changing ovet time neither is subjectivity\n",
    "sentiment_over_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.046731</td>\n",
       "      <td>0.474978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.038213</td>\n",
       "      <td>0.436526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.052158</td>\n",
       "      <td>0.475796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.064343</td>\n",
       "      <td>0.457058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.031493</td>\n",
       "      <td>0.444088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       polarity  subjectivity\n",
       "topic                        \n",
       "0      0.046731      0.474978\n",
       "1      0.038213      0.436526\n",
       "2      0.052158      0.475796\n",
       "3      0.064343      0.457058\n",
       "4      0.031493      0.444088"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_by_topic = data.groupby('topic').agg({'subjectivity': np.mean, 'polarity': np.mean, })\n",
    "#also not big differences by topic\n",
    "sentiment_by_topic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Clinton'] = data['body'].apply(lambda x : True if 'clinton' in x.lower() or 'hilary' in x.lower() else False)\n",
    "data['Trump'] = data['body'].apply(lambda x : True if 'trump' in x.lower() or 'donald' in x.lower() else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06337006754296344, 0.04930149277822336)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinton_sentiment = np.mean(data[data['Clinton']]['polarity'])\n",
    "trump_sentiment = np.mean(data[data['Trump']]['polarity'])\n",
    "clinton_sentiment, trump_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>post_count</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2013</th>\n",
       "      <th>1</th>\n",
       "      <td>-0.197586</td>\n",
       "      <td>4</td>\n",
       "      <td>0.475020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.086819</td>\n",
       "      <td>9</td>\n",
       "      <td>0.352403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.018503</td>\n",
       "      <td>3</td>\n",
       "      <td>0.513577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.025568</td>\n",
       "      <td>1</td>\n",
       "      <td>0.477273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.060191</td>\n",
       "      <td>2</td>\n",
       "      <td>0.456490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            polarity  post_count  subjectivity\n",
       "year month                                    \n",
       "2013 1     -0.197586           4      0.475020\n",
       "     2      0.086819           9      0.352403\n",
       "     3      0.018503           3      0.513577\n",
       "     4     -0.025568           1      0.477273\n",
       "     5      0.060191           2      0.456490"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinton_over_time = data[data['Clinton']].groupby(['year', 'month']).agg({'polarity': np.mean, 'subjectivity': np.mean, 'body': 'count'}).rename(columns= {'body': 'post_count'})\n",
    "clinton_over_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>post_count</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2013</th>\n",
       "      <th>1</th>\n",
       "      <td>-0.005309</td>\n",
       "      <td>3</td>\n",
       "      <td>0.687811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.150000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.248398</td>\n",
       "      <td>2</td>\n",
       "      <td>0.485931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            polarity  post_count  subjectivity\n",
       "year month                                    \n",
       "2013 1     -0.005309           3      0.687811\n",
       "     3      0.150000           1      0.650000\n",
       "     4      0.000000           1      0.500000\n",
       "     5      0.248398           2      0.485931\n",
       "     6      0.400000           2      0.775000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump_over_time = data[data['Trump']].groupby(['year', 'month']).agg({'polarity': np.mean, 'subjectivity': np.mean, 'body': 'count'}).rename(columns= {'body': 'post_count'})\n",
    "trump_over_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit\n",
       "business               14\n",
       "democrats              48\n",
       "education               2\n",
       "energy                  5\n",
       "environment            22\n",
       "feminisms               6\n",
       "history                70\n",
       "law                    26\n",
       "moderatepolitics       16\n",
       "news                 2369\n",
       "politics            13012\n",
       "progressive            24\n",
       "racism                  8\n",
       "socialism             113\n",
       "ukpolitics            685\n",
       "uspolitics             10\n",
       "worldevents             5\n",
       "worldnews            3457\n",
       "worldpolitics         108\n",
       "Name: body, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('subreddit')['body'].count() #not enough in a lot of subreddits for much divided analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (optional) Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sentiment Analysis "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
